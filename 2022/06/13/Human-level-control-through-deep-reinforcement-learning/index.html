<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="-jCet6qPD7nML4-W6IY2HZwfSblJyWta_Jx7_AGHgIk">
  <meta name="baidu-site-verification" content="f349dc627a72ee616d62ed513574025d">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/orange/pace-theme-center-circle.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"weirdozz.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="摘要 为了能够将强化学习应用到现实难度的场景下，代理端就会面临一个困难的任务：从高维传感其中获取高效的环境表示，并且以此来总结过去的经验应用到新的状态中。尽管强化学习已经在许多邻域获得了成功，但是其应用性局限于某些特定的邻域，这些邻域要么是能够获取有效的特征要么是有充分研究过的低维状态空间。本文中作者使用训练深度神经网络的技术来发展一个新的人工代理，称之为深度Q网络，能够直接从高维输入中学习有效的">
<meta property="og:type" content="article">
<meta property="og:title" content="Human-level control through deep reinforcement learning">
<meta property="og:url" content="https://weirdozz.github.io/2022/06/13/Human-level-control-through-deep-reinforcement-learning/index.html">
<meta property="og:site_name" content="Weirdo">
<meta property="og:description" content="摘要 为了能够将强化学习应用到现实难度的场景下，代理端就会面临一个困难的任务：从高维传感其中获取高效的环境表示，并且以此来总结过去的经验应用到新的状态中。尽管强化学习已经在许多邻域获得了成功，但是其应用性局限于某些特定的邻域，这些邻域要么是能够获取有效的特征要么是有充分研究过的低维状态空间。本文中作者使用训练深度神经网络的技术来发展一个新的人工代理，称之为深度Q网络，能够直接从高维输入中学习有效的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.imgur.com/gN9yGcz.png">
<meta property="og:image" content="https://i.imgur.com/Nzibkyi.png">
<meta property="og:image" content="https://i.imgur.com/l2fSGMq.png">
<meta property="og:image" content="https://i.imgur.com/YiFftuY.png">
<meta property="og:image" content="https://i.imgur.com/3vDRsqY.png">
<meta property="og:image" content="https://i.imgur.com/JNkUraJ.png">
<meta property="article:published_time" content="2022-06-13T11:55:39.000Z">
<meta property="article:modified_time" content="2023-12-27T12:42:30.263Z">
<meta property="article:author" content="Weirdo">
<meta property="article:tag" content="WeirdoBlog">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.imgur.com/gN9yGcz.png">


<link rel="canonical" href="https://weirdozz.github.io/2022/06/13/Human-level-control-through-deep-reinforcement-learning/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://weirdozz.github.io/2022/06/13/Human-level-control-through-deep-reinforcement-learning/","path":"2022/06/13/Human-level-control-through-deep-reinforcement-learning/","title":"Human-level control through deep reinforcement learning"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Human-level control through deep reinforcement learning | Weirdo</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Weirdo</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
        <li class="menu-item menu-item-movies"><a href="/movies/" rel="section"><i class="fa fa-film fa-fw"></i>电影</a></li>
        <li class="menu-item menu-item-books"><a href="/books/" rel="section"><i class="fa fa-book fa-fw"></i>书籍</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81-8"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%95%E8%A8%80-8"><span class="nav-number">2.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%B9%E6%B3%95-7"><span class="nav-number">3.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">3.1.</span> <span class="nav-text">预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84-2"><span class="nav-number">3.2.</span> <span class="nav-text">模型架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82"><span class="nav-number">3.3.</span> <span class="nav-text">训练细节</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E6%B3%95"><span class="nav-number">3.4.</span> <span class="nav-text">算法</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Weirdo"
      src="/images/weirdo.jpg">
  <p class="site-author-name" itemprop="name">Weirdo</p>
  <div class="site-description" itemprop="description">怕什么真理无穷，进一步有进一步的欢喜</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://weirdozz.github.io/2022/06/13/Human-level-control-through-deep-reinforcement-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/weirdo.jpg">
      <meta itemprop="name" content="Weirdo">
      <meta itemprop="description" content="怕什么真理无穷，进一步有进一步的欢喜">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weirdo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Human-level control through deep reinforcement learning
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-13 19:55:39" itemprop="dateCreated datePublished" datetime="2022-06-13T19:55:39+08:00">2022-06-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-12-27 20:42:30" itemprop="dateModified" datetime="2023-12-27T20:42:30+08:00">2023-12-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2022/06/13/Human-level-control-through-deep-reinforcement-learning/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/06/13/Human-level-control-through-deep-reinforcement-learning/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="摘要-8">摘要</h2>
<p>为了能够将强化学习应用到现实难度的场景下，代理端就会面临一个困难的任务：从高维传感其中获取高效的环境表示，并且以此来总结过去的经验应用到新的状态中。尽管强化学习已经在许多邻域获得了成功，但是其应用性局限于某些特定的邻域，这些邻域要么是能够获取有效的特征要么是有充分研究过的低维状态空间。本文中作者使用训练深度神经网络的技术来发展一个新的人工代理，称之为深度Q网络，能够直接从高维输入中学习有效的策略。</p>
<span id="more"></span>
<h2 id="引言-8">引言</h2>
<p>本文的任务情景是代理通过一系列的观察，行动和奖励与环境进行交互。代理的目标是以一种最大化未来累计奖励的方法选择行动。公式上来说就是以深度卷积神经网络来近似最优动作-值函数</p>
<p><img src="https://i.imgur.com/gN9yGcz.png" alt="picture 1"></p>
<p>就是每个时间步t根据策略 $\pi=P(a|s)$ 在 $\gamma$ 折扣下的最大累计奖励。</p>
<p>作者使用卷积网络参数化了一个近似值函数 $Q(s,a;\theta_i)$ ，如下图所示，其中 $\theta_i$ 是在第i次迭代时候的参数（weight）。为了实现经验回放，作者存储代理在每个时间步的经验 $e=(s_t,a_t,r_t,s_{t+1})$ 到数据集 $D_t={e_1,…,e_t}$ 上。学习过程中，在样本 $s,ar,s’$ 上使用Q学习，样本是从数据中随机正态抽取的。Q学习每一次迭代i都是用如下的损失函数进行更新</p>
<p><img src="https://i.imgur.com/Nzibkyi.png" alt="picture 2"></p>
<p>其中 $\theta_i$ 是Q网络在第i次迭代的参数， $\theta_i^-$ 是用于计算target的网络参数。</p>
<h2 id="方法-7">方法</h2>
<h3 id="预处理">预处理</h3>
<p>直接使用Atari2600框架，是210×160像素的128色盘图片。采用基础的预处理步骤以减少输入的维度和并且处理其中的一些人为因素。首先，为了编码单个帧，我们取被编码帧和前一帧上每个像素颜色值的最大值。这对于消除游戏中出现的闪烁(有些对象只出现在偶数帧中，而有些对象只出现在奇数帧中)是必要的。其次，其次，我们从RGB帧中提取Y通道，也称为亮度，并将其缩放为84×84。下面的算法1使用这种方法对最近的m帧进行操作然后进行堆叠以产生Q函数的输入。</p>
<h3 id="模型架构-2">模型架构</h3>
<p>因为Q将历史-动作对映射到他们的Q值的标量估计上，历史和动作已经被一些网络用作输入了。但是这样做有一个缺点，需要独立的前向传播以计算每个动作的Q值，使得成本与动作数量呈线性关系。作者使用的架构对于每一个可能的动作都有一个独立的输出单元，并且网络的输入只有一个状态表示，输出是对应的输入的每个独立动作的预测Q值。这种架构的好处就是通过一次前向传播就可以计算一个给定状态下的所有可能的行动的Q值。</p>
<p>网络的具体结构如下图所示。神经网路的输入由预处理映射 $\phi$ 生成的84×84×4的图像组成。第一个隐藏层使用32个8×8的步幅为4的卷积核与输入图像进行卷积，并且使用一个ReLU。第二个卷积层使用64个4×4的步幅为2的卷积核，也使用ReLU。第三个卷积层使用一个64个3×3的卷积核，使用ReLU。最后的隐藏层是一个全连接层，由512个隐藏单元组成。输出层是一个全连接层，其隐藏单元数量等于可能的行动数。</p>
<p><img src="https://i.imgur.com/l2fSGMq.png" alt="picture 3"></p>
<h3 id="训练细节">训练细节</h3>
<p>因为不同游戏间的分数差异是不同的，因此作者将奖励只分为正负1，0作为不奖励。实验中使用了RMSProp算法并且batch大小设置为32。训练过程中的行为策略是 $\epsilon$ 贪心法，$\epsilon$ 在前100万帧从1.0-0.1线性变化，并且最终固定在0.1。总共训练5千万帧，使用100万个最近帧作为复现记忆。</p>
<p>与之前的方法类似，作者同样使用了跳帧技术。代理每k帧做一个行为而不是每一帧都要做，且最后一个行为在跳跃的帧上进行重复。因为运行一步需要的计算比代理选择行为的计算要少，这种技术允许代理在不显著增加运行时间的情况下多玩k次游戏。本文设置的k为4。</p>
<h3 id="算法">算法</h3>
<p>每个时间步代理都会选择一个行为 $a_t$ 。行为被传递到模拟器并且改变内部状态和游戏得分。模拟器的内部状态是对代理不可见的，代理只观察来自模拟器的图像，即一个表示当前屏幕的向量。此外还会接收一个奖励 $r_t$ 表示游戏得分的改变。由于代理只能观察当前屏幕，因此任务只能被部分观察到，并且不可能只通过对当前的屏幕状态就能完全理解当前的情况。所以一系列的行为和观察 $s_t=x_1,a_1,x_2,a_2,…,a_{t-1},x_t$ 会被传入算法中，然后根据这些序列学习游戏的策略。这个式子给出了一个大的但是有限的马尔科夫链，每一个序列都是一个状态。因此，可以使用标准的强化学习方法，即只使用完整的序列 $s_t$ 作为时间t的状态表示。</p>
<p>作者使用标准假设，即未来的奖励积累根据 $\gamma$ 每个时间步进行折扣，定义未来时间步t的折扣返回为 $R_t=\sum_{t’=t}^{T}\gamma^{t’-t}r_{t’}$ ，其中T是整个时间步结束的时刻。定义最优行动-值函数为 $Q^*{s,a}=max_\pi E[R_t|s_t=s,a_t=a,\pi]$ 。</p>
<p>根据Bellman灯饰，如果序列 $s’$ 在下个时间步的最优值 $Q^*{s,a}$ 对于所有的行为 $a’$ 是已知的 ，最优策略就是选择行为 $a’$ 以最大化奖励值</p>
<p><img src="https://i.imgur.com/YiFftuY.png" alt="picture 4"></p>
<p>但是该方法的实际应用不太好，因此使用一个Q网络。Q网络通过在每次迭代过程中训练参数 $\theta_i$ 以最小化Bellman公式的均方误差，其中最优的解 $r+\gamma max_{a’}Q^*(s’,a’)$ 被替换为 $y=r+\gamma max_{a’}Q(s’,a’;\theta_i^-)$ 。这样第i次迭代的时候的损失函数就应该是</p>
<p><img src="https://i.imgur.com/3vDRsqY.png" alt="picture 5"></p>
<p>可以注意到标签是根据网络的权重来生成的，这与传统的有监督学习的固定标签是不同的。在每个优化阶段，使用上一次迭代产生的参数来生成这一次迭代的损失。最终的梯度公式可以表示为</p>
<p><img src="https://i.imgur.com/JNkUraJ.png" alt="picture 6"></p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/05/30/What-Happens-Next-Event-Prediction-Using-a-Compositional-Neural-Network-Model/" rel="prev" title="What Happens Next? Event Prediction Using a Compositional Neural Network Model">
                  <i class="fa fa-chevron-left"></i> What Happens Next? Event Prediction Using a Compositional Neural Network Model
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/10/23/CircEvent/" rel="next" title="CircEvent">
                  CircEvent <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Weirdo</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/pace.js"></script>

  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"weirdoblog","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
